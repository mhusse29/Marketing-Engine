# LLM Provider Configuration Audit

## Overview
This document provides a comprehensive audit of all LLM provider configurations across the Marketing Engine application.

---

## ‚úÖ Current LLM Provider Setup

### 1. **BADU Assistant (Chat Interface)**
- **Provider**: OpenAI
- **Model**: `gpt-5-chat-latest` (GPT-5 Chat)
- **Location**: `server/ai-gateway.mjs` - Line 404
- **Endpoint**: `/v1/chat`
- **Configuration**:
  ```javascript
  const OPENAI_CHAT_MODEL = 'gpt-5-chat-latest'  // BADU Assistant - chat-optimized GPT-5
  ```
- **Features**:
  - 400K token context window
  - Enhanced reasoning capabilities
  - Optimized for conversational interactions
  - Chat history support (last 6 messages)
  - Attachment metadata support
- **System Prompt**: Lines 1870-2563 (server/ai-gateway.mjs)
  - Defines BADU's personality and capabilities
  - Includes knowledge about all panels, providers, and settings
  - Updated with latest video provider information

### 2. **Content Panel - Brief Refine**
- **Provider**: OpenAI
- **Model**: `gpt-5` (Primary) / `gpt-4o` (Fallback)
- **Location**: `server/ai-gateway.mjs` - Line 1695
- **Endpoint**: `/v1/tools/brief/refine`
- **Configuration**:
  ```javascript
  const OPENAI_PRIMARY_MODEL = 'gpt-5'  // Content Panel - highest quality
  const OPENAI_FALLBACK_MODEL = 'gpt-4o'  // Stable fallback
  ```
- **Features**:
  - Refines creative briefs
  - Supports attachments (images, PDFs)
  - Temperature: 0.35 (focused refinement)
  - Max tokens: 600
  - Fallback logic if primary fails

### 3. **Content Panel - Content Generation**
- **Provider**: OpenAI
- **Model**: `gpt-5` (Primary) / `gpt-4o` (Fallback)
- **Location**: `server/ai-gateway.mjs` - Line 197, 288
- **Endpoint**: `/v1/generate`
- **Features**:
  - Multi-platform content generation
  - JSON structured output
  - Dynamic token allocation (320-850 tokens)
  - Temperature: 0.6-0.7 (balanced creativity)
  - Persona, tone, CTA support
  - Platform-specific optimization

### 4. **Pictures Panel - Prompt Suggestion**
- **Provider**: **LOCAL FUNCTION** (No LLM)
- **Location**: `src/store/picturesPrompts.ts` - `craftPicturesPrompt()`
- **Method**: Rule-based prompt construction
- **Features**:
  - Combines user settings into structured prompts
  - Style, aspect ratio, lighting, composition
  - Brand color locking
  - No API calls - instant generation
  - 4000 character limit

**‚ö†Ô∏è Note**: Pictures panel does NOT use an LLM for prompt suggestions. It uses a deterministic template system that combines user selections into a formatted prompt.

### 5. **Pictures Panel - Image Generation**
- **Providers**: Multiple AI image generation services
- **Location**: `server/ai-gateway.mjs`
- **Supported Providers**:
  1. **OpenAI DALL-E 3** (Default)
     - Model: `dall-e-3`
     - Quality: Standard / HD
     - Style: Vivid / Natural
  2. **FLUX Pro** (BFL.ml)
     - API: `https://api.bfl.ml/v1`
     - Model: `flux-pro-1.1`
     - Advanced aspect ratios
  3. **Stability AI** (SD 3.5)
     - Model: `sd3.5-large-turbo`
     - CFG scale control
     - Negative prompts
  4. **Ideogram**
     - Models: v1, v2, turbo
     - Typography specialization
     - Style types (10+ options)

---

## üìã LLM Provider Summary Table

| Feature | Provider | Model | Endpoint | Purpose |
|---------|----------|-------|----------|---------|
| BADU Chat | OpenAI | gpt-5-chat-latest | `/v1/chat` | Conversational AI assistant |
| Brief Refine | OpenAI | gpt-5 / gpt-4o | `/v1/tools/brief/refine` | Creative brief enhancement |
| Content Generation | OpenAI | gpt-5 / gpt-4o | `/v1/generate` | Multi-platform content |
| Pictures Prompt | **Local** | **Rule-based** | Client-side | Prompt construction |
| Pictures Generation | Multiple | DALL-E 3, FLUX, SD3.5, Ideogram | `/v1/images/generate` | Image creation |
| Video Generation | Multiple | Veo-3, Ray-2 | `/v1/videos/generate` | Video creation |

---

## ‚úÖ BADU Knowledge Verification

### Current BADU Capabilities (as of system prompt):

1. **Content Panel Knowledge** ‚úì
   - Creative brief input
   - Refine button functionality
   - Persona, tone, CTA, language options
   - Platform selection
   - Validate button workflow

2. **Pictures Panel Knowledge** ‚úì
   - Provider selection (DALL-E 3, FLUX, Stability, Ideogram)
   - Prompt suggestion feature
   - Style, aspect ratio, lighting options
   - Brand color locking
   - Advanced settings per provider

3. **Video Panel Knowledge** ‚úÖ **UPDATED**
   - Provider selection (Runway, Luma)
   - Runway Veo-3 features
   - Luma Ray-2 Dream Machine
   - Camera movements
   - Visual styles, lighting
   - Motion speed, subject focus
   - Film look, color grading
   - Depth of field
   - Loop support (Luma)

4. **Settings & Options** ‚úì
   - Campaign settings
   - Version control
   - Platform configuration
   - Export capabilities

---

## üîß Configuration Files

### Environment Variables Required:
```env
# AI LLM Provider
OPENAI_API_KEY=sk-...

# Image Generation Providers
FLUX_API_KEY=...
STABILITY_API_KEY=...
IDEOGRAM_API_KEY=...

# Video Generation Providers
RUNWAY_API_KEY=...
LUMA_API_KEY=...
```

### Gateway Configuration:
- **File**: `server/ai-gateway.mjs`
- **Models Defined**: Lines 399-408
- **Health Check**: GET `/health` (shows all provider status)
- **Mock Mode**: `MOCK_OPENAI=1` (for testing)

---

## üéØ Recommendations

### ‚úÖ All Systems Configured Correctly

1. **BADU** - Using optimal GPT-5-chat-latest model
2. **Content Refine** - Using GPT-5 with fallback
3. **Content Generation** - Using GPT-5 with fallback
4. **Pictures Prompt** - Local function (no changes needed)
5. **Image Generation** - Multiple providers configured
6. **Video Generation** - Runway & Luma configured

### üîÑ Future Enhancements (Optional)

1. **Add LLM to Pictures Prompt Suggestion**
   - Could enhance with GPT-5 for creative suggestions
   - Current rule-based system is fast and deterministic
   - Consider as optional "AI-enhanced" mode

2. **Video Prompt Enhancement**
   - Add AI-assisted prompt refinement (like content panel)
   - Help users craft better video prompts
   - Suggest camera movements and styles

3. **Multi-LLM Support**
   - Add Claude 3.5 Sonnet as alternative
   - Add Gemini 1.5 Pro as option
   - Allow user to choose preferred LLM

---

## üìä API Key Status Check

To verify all providers are configured, visit:
```
GET http://localhost:8787/health
```

Expected Response:
```json
{
  "ok": true,
  "providerPrimary": "openai",
  "primaryModel": "gpt-5",
  "chatModel": "gpt-5-chat-latest",
  "fallbackModel": "gpt-4o",
  "hasOpenAI": true,
  "imageProviders": {
    "openai": true,
    "flux": true,
    "stability": true,
    "ideogram": true
  },
  "videoProviders": {
    "runway": true,
    "luma": true
  }
}
```

---

## ‚úÖ Audit Complete

**Date**: October 8, 2025  
**Status**: All LLM providers correctly configured  
**Lint Status**: All errors fixed ‚úì  
**BADU Knowledge**: Up to date with latest video providers ‚úì  

No missing LLM provider configurations detected.
